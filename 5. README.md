# GenAI with Intel® OpenVINO™

This repository provides resources and examples for running Generative AI (GenAI) and performing large language model (LLM) inference on Intel AI laptops using Intel® OpenVINO™. It also includes instructions for fine-tuning LLM models and optimizing them for efficient deployment on Intel hardware.

## Directory Structure

- `convert_model/`: Contains scripts for model conversion.
- `inference/`: Contains scripts for running inference.
- `fine_tuning/`: Contains scripts for fine-tuning models.

## Requirements

- Intel® OpenVINO™ Toolkit
- PyTorch
- Transformers
- NumPy

Install the required Python packages:
```sh
pip install -r requirements.txt
